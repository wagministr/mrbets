# ğŸ“˜ CONTEXT.md â€” Project Overview for MrBets.ai
_Last updated: 2025-04-29_

---

## ğŸ¯ Project Evolution: MrBets.ai (Formerly WinPulse)

MrBets.ai is an AI-powered sports prediction platform that delivers pre-analyzed football match insights based on comprehensive data collection, advanced AI reasoning, and betting value assessment.

The project is evolving from a Next.js-only application with serverless functions to a robust monorepo architecture with a dedicated FastAPI backend for enhanced data processing capabilities.

---

## ğŸ—ï¸ Architecture Overview

### Current Architecture
- **Frontend**: Next.js 14 with App Router deployed on Vercel
- **Database**: Supabase (PostgreSQL)
- **API Integrations**: API-Football, OpenAI
- **Automation**: Vercel Cron Jobs

### Planned Architecture
- **Frontend**: Next.js 14 (unchanged) + Telegram Bot 
- **Backend**: FastAPI with microservices architecture
- **Data Processing**: Redis Streams for distributed processing. **Pre-processor (`pre_processor.py`) now handles translation, chunking, NER, entity linking (teams, players to Supabase IDs), OpenAI embeddings, and storage of processed documents to Supabase (`processed_documents` table) and chunk vectors to Pinecone.**
- **Vector Search**: Pinecone for semantic retrieval. **The `pre_processor.py` now actively populates the Pinecone index.**
- **Storage**: Supabase Storage for raw data (still relevant for original large files if needed, though `pre_processor` focuses on structured DB entries).
- **Additional Data Sources**: News sites, social media, video content

---

## ğŸ§© Key Functional Components

### 1. ğŸ”„ **Fixtures Sync**
- Uses `API-Football` to fetch upcoming matches from select leagues (e.g., Premier League, La Liga)
- **Current**: Script: `/scripts/updateFixtures.ts` (Legacy frontend script, to be deprecated)
- **Implemented (Backend)**: Python service: `backend/jobs/scan_fixtures.py`
  - Fetches upcoming fixtures from API-Football for a configurable list of leagues and a defined forward window (e.g., 30 days).
  - Stores detailed fixture data in Supabase `fixtures` table (includes IDs, teams, event date, status, scores, and full API response).
  - Adds new `fixture_id`s to a Redis queue (`queue:fixtures`) for further processing.
  - Employs a Redis set for de-duplication to prevent re-processing recently scanned fixtures within a TTL (e.g., 24 hours).
  - Supports a test mode for fetching data from a past season to aid development during off-seasons.
- Stores match data into `Supabase.fixtures`
- Triggered via cron job

### 1.A. ğŸ§‘â€ğŸ¤â€ğŸ§‘ **Metadata Sync (Teams & Players)**
- **Implemented (Backend)**: Python service `backend/fetchers/metadata_fetcher.py`
  - Fetches comprehensive data for teams (including name, country, venue details like name, city, capacity, image) and players (name, nationality, age, height, photo, and season-specific stats like appearances, goals, rating if provided by API) from API-Football.
  - Populates/updates the Supabase tables `teams` and `players`.
  - Operates on a configurable list of leagues and a specified season to ensure contextual relevance of player statistics.
  - This script is typically run on-demand or less frequently than fixture scanning, to build and maintain a local cache of team/player metadata.

### 2. ğŸ§  **AI Prediction Generation**
- Each match is processed by:
  - Fetching live stats & odds
  - Formatting a structured prompt
  - Sending to OpenAI (model: `o4-mini`, planned upgrade to `GPT-4o`)
  - Parsing AI response into:
    - `CHAIN OF THOUGHT`
    - `FINAL PREDICTION`
    - `VALUE BETS`

- **Planned**: Pipeline: 
  - Data collection via various fetchers
  - Pre-processing via `/backend/processors/pre_processor.py`
  - Retrieval via `/backend/processors/retriever_builder.py`
  - LLM reasoning via `/backend/processors/llm_reasoner.py`
- All results are stored in `Supabase.ai_predictions`

### 3. ğŸ“… **Automated Processing**

- **Planned**: Continuous processing:
  - Data collection every 30 minutes via cron
  - Redis Streams for distributed processing
  - Auto-refresh when significant changes detected (odds shifts, new content)

### 4. ğŸ’¬ **User-Facing /ai Page**
- Users visit `/ai`
- See horizontally scrollable cards of upcoming matches
- Clicking a card:
  - Opens the prediction display
  - Loads prediction from `Supabase.ai_predictions`
  - Displays:
    - Chain of Thought
    - Final Prediction
    - List of Top 3 Value Bets
- If no prediction exists:
  - Fallback message: "AI prediction is being prepared..."

### 5. ğŸ” **Auth & Visibility**
- Top matches in `/ai` preview are blurred unless the user logs in
- Login is email-based (OTP) using Supabase Auth
- After login, full dashboard unlocked

---

## ğŸ”’ Database Structure (Supabase)

### Current Tables

#### `fixtures`
- `fixture_id`: integer (primary key)
- `league_id`: integer
- `home_id`: integer
- `away_id`: integer
- `utc_kickoff`: timestamp
- `status`: text
- `score_home`: integer
- `score_away`: integer
- `last_updated`: timestamp 

#### `ai_predictions`
- `id`: uuid (primary key)
- `fixture_id`: integer (foreign key)
- `type`: text (e.g., "pre-match")
- `chain_of_thought`: text
- `final_prediction`: text
- `value_bets_json`: string (stringified array)
- `model_version`: text
- `generated_at`: timestamp
- `stale`: boolean (default: false)

#### `raw_events`
- `id`: uuid (primary key)
- `match_id`: integer (foreign key)
- `source`: text (e.g., "twitter", "bbc", "youtube")
- `content_hash`: text (for deduplication)
- `content_path`: text (path in Supabase Storage)
- `metadata`: jsonb
- `reliability_score`: float
- `created_at`: timestamp

#### `emb_cache`
- `hash`: text (primary key)
- `vector`: vector (1536d)
- `created_at`: timestamp

---

## ğŸ“¡ External APIs & Models

### Current Integrations

#### âœ… API-Football
- Used for: Fixtures, live odds, team data, predictions, league standings, player statistics, venue information.
- Called via `lib/apiFootball.ts` (Legacy Frontend) and backend Python scripts (`backend/jobs/scan_fixtures.py`, `backend/fetchers/metadata_fetcher.py`, `backend/fetchers/rest_fetcher.py`).
- Rate-limited API with key-based access

#### âœ… The Odds API
- Used for: Fetching pre-match and live odds from multiple bookmakers.
- Called via: `backend/fetchers/odds_fetcher.py`
- Rate-limited API with key-based access (`ODDS_API_KEY`).
- Integrated with Redis Streams for `raw_events` and Supabase Storage for snapshots.

#### âœ… Scraper Fetcher (BBC Sport RSS)
- Use: Scraping news articles from BBC Sport RSS feeds.
- Called via: `backend/fetchers/scraper_fetcher.py`
- Uses `httpx`, `BeautifulSoup4`, `feedparser` for fetching and parsing HTML/RSS.
- Uses `spacy` for Named Entity Recognition (NER) from article text.
- Extracts article title, full text, images, and entities.
- Pushes structured data to Redis Streams (`raw_events`) and saves raw text to Supabase Storage.

### Planned Integrations

#### â³ OpenAI
- Used for: Text generation (reasoning, summary, betting logic)
- Model: `o4-mini`
- Called via `generatePrediction.ts` â†’ OpenAI Chat Completion endpoint
- Responses are split into 3 sections and stored

#### â³ OpenAI Embeddings
- Use: Vectorizing text for semantic search
- Model: `text-embedding-3-small` (as implemented in `pre_processor.py`)
- Will be called via: `/backend/processors/pre_processor.py` (**Implemented**)

#### â³ Pinecone
- Use: Vector database for similar document retrieval
- Will store all processed text embeddings. **Populated by `pre_processor.py`.**
- Will be queried for context retrieval for each match

#### â³ BeautifulSoup + Requests
- Use: Scraping news sites and sports blogs
- Will extract clean text from HTML

#### â³ Yandex Cloud API
- Use: Translation services for non-English content
- Will ensure all analysis happens on English text

#### â³ Whisper
- Use: Transcription of YouTube videos and podcasts
- Model: medium or large-v3
- Will convert audio analysis to searchable text

#### â³ Twitter/Telegram APIs
- Use: Gathering expert opinions and community insights
- Will capture real-time discussions about upcoming matches

---

## ğŸ“Š Data Flow Pipeline 

```
[CRON] â†’ scan_fixtures.py â†’ redis:queue:fixtures (LIST) â†’ worker_manager
                                       â”‚ POP
                                       â–¼
                   Â«data-collector workflowÂ» (fan-out fetcher tasks)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ rest_fetcher.py (API-Football)       â†’ raw_events (STREAM)          â”‚
â”‚ odds_fetcher.py (The Odds API)       â†’ raw_events (STREAM)          â”‚
â”‚ scraper_fetcher.py (BBC/ESPN)        â†’ raw_events (STREAM)          â”‚
â”‚ twitter_fetcher.py (filtered stream) â†’ raw_events (STREAM)          â”‚
â”‚ telegram_fetcher.py (bot getUpdates) â†’ raw_events (STREAM)          â”‚
â”‚ youtube_fetcher.py (yt-dlp+Whisper)  â†’ raw_events (STREAM)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼ consumer-group:pre_processor (parallel workers)
-    translate â†’ split_chunks â†’ reliability_score â†’ embeddings â†’ Storage/Pinecone/Postgres
+    (pre_processor.py: translate â†’ chunk â†’ NER â†’ link entities (Supabase) â†’ embeddings (OpenAI) â†’ store (Supabase `processed_documents`, Pinecone vectors))
                     â–¼
           retriever_builder.py (sql filter + pinecone topK + dedup)
                     â–¼
           llm_reasoner.py (prompt + live odds â†’ GPT-4o) â†’ JSON
                     â–¼
           result_writer.py (UPSERT predictions, TTL 3h)
```

This pipeline will run automatically every 30 minutes, constantly updating the data store with fresh information and generating new predictions when needed.

---

## ğŸ§ª Development Environment

### Current Environment
- Project is developed on Windows 11 + Linux WSL
- Docker + docker-compose for full system simulation
- Backend development in Python 3.11
- Frontend continues with Next.js/TypeScript
- Environment variables split between frontend and backend needs

---

## ğŸ’» Repository Structure (Planned)

```
mrbets/                         # Repository root
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ app/                    # Main FastAPI code
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ common.py
â”‚   â”‚   â”‚   â”œâ”€â”€ fixture.py
â”‚   â”‚   â”‚   â”œâ”€â”€ fixtures.py
â”‚   â”‚   â”‚   â”œâ”€â”€ prediction.py
â”‚   â”‚   â”‚   â””â”€â”€ predictions.py
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ fixtures.py
â”‚   â”‚   â”‚   â””â”€â”€ predictions.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ config.py
â”‚   â”‚       â”œâ”€â”€ exceptions.py
â”‚   â”‚       â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ fetchers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metadata_fetcher.py
â”‚   â”‚   â”œâ”€â”€ rest_fetcher.py
â”‚   â”‚   â”œâ”€â”€ odds_fetcher.py
â”‚   â”‚   â””â”€â”€ scraper_fetcher.py
â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â”œâ”€â”€ scan_fixtures.py
â”‚   â”‚   â””â”€â”€ worker.py
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ pre_processor.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ requirements-dev.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ env.example
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ .flake8
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ observer.py
â”‚   â”œâ”€â”€ check_fixtures.py
â”‚   â”œâ”€â”€ test_services.py
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ frontend/                   # Next.js 14 frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ globals.css
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ .eslintrc.json
â”‚   â”œâ”€â”€ next-env.d.ts
â”‚   â”œâ”€â”€ next.config.js
â”‚   â”œâ”€â”€ postcss.config.js
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ .vscode/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml
â”‚       â”œâ”€â”€ root-ci.yml
â”‚       â””â”€â”€ frontend-lint.yml
â”œâ”€â”€ cron/
â”‚   â”œâ”€â”€ crontab
â”‚   â”œâ”€â”€ run_scan.sh
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ observer.log
â”œâ”€â”€ scripts/
â”œâ”€â”€ node_modules/
â”œâ”€â”€ package.json
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .gitignore
â”œâ”€â”€ env.example
â”œâ”€â”€ .flake8
â”œâ”€â”€ README.md
â”œâ”€â”€ CONTEXT.md
â””â”€â”€ BACKEND.md
---

Only basic fetcher and processor modules are implemented in backend/; other directories exist but are currently empty.
Specifically, `rest_fetcher.py`, `odds_fetcher.py`, and `scraper_fetcher.py` are now available.
The frontend/ is a Next.js 14 scaffold without business logic.
The monitoring/ directory is missing.
The scripts/ directory is empty or contains only stubs.
The cron/ directory contains a crontab and helper scripts.
.github/workflows/ provides CI/CD for both frontend and backend.
The logs/ directory is used for backend logs.


## ğŸ”œ Project Timeline (May 9 â†’ August 9)

| Period | Goal | Deliverables |
|--------|------|--------------|
| May 09â€“15 | Dev environment + CI | docker-compose, GitHub Actions |
| May 16â€“22 | Queue demo | fixtures-scanner, Redis with tasks |
| May 23â€“29 | REST/Scraper fetchers | BBC + API-Football data in DB |
| May 30â€“Jun 05 | Whisper pipeline | YouTube texts in Storage/Postgres |
| Jun 06â€“12 | Pre-processor | Translation, chunks, embeddings |
| Jun 13â€“19 | Vector search | Pinecone Top-K API ready |
| Jun 20â€“26 | Retriever API | `/context/{match_id}` returns facts |
| Jun 27â€“Jul 03 | LLM draft | First JSON prediction saved |
| Jul 04â€“10 | TTL cache | Reading `predictions` on frontend |
| Jul 11â€“17 | Odds module | Live odds in prompt |
| Jul 18â€“24 | Frontend integration | Next.js match page shows prediction |
| Jul 25â€“31 | Affiliate links | Smart links + GTM events |
| Aug 01â€“07 | Load testing | 100 matches, <2 sec latency |
| Aug 08â€“09 | UI polish and release | Landing, animation, prod deploy |

---

## ğŸ”‘ Key Terms

| Term | What it is | In simple words |
|------|------------|----------------|
| **Redis** | In-memory data store | Ultra-fast task queue between services |
| **Redis Streams** | Message broker pattern | Ordered message queue with consumer groups |
| **Embeddings** | Text vectorization | Representing text meaning as numbers for search |
| **Hybrid Search** | Filter + vector search | First by team/date, then by meaning |
| **TTL** | Time To Live | Prediction validity period (3 hours) |
| **Chain-of-Thought** | Prompting method | LLM explicitly shows reasoning process |
| **Pinecone** | Vector database | Stores and searches semantically similar texts |
| **Whisper** | Speech recognition model | Converts YouTube audio to text |
| **FastAPI** | Python web framework | High-performance API with automatic documentation |
| **BeautifulSoup** | HTML parser | Extracts text from web pages |

---

## ğŸ“‹ First Tasks (By May 9)

1. Set up monorepo structure (frontend/ and backend/ directories)
2. Create docker-compose.yml for three services (frontend, backend, redis)
3. Install WSL 2 and Docker Desktop on Windows
4. Set up Supabase project with initial tables
5. Create `.env.example` template with all required API keys
6. Implement `scan_fixtures.py` script for fetching matches
7. Create demo worker to validate Redis queue functionality
8. Ensure documentation (BACKEND.md) is up to date

---

This file is the **single source of truth** for how the platform is designed to work.  
Keep it updated when functionality evolves.

## ğŸ“ Update: 2025-05-10 - ĞœĞ¾Ğ½Ğ¾Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ Ñ FastAPI Backend

Ğ ĞµĞ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ² Ğ¼Ğ¾Ğ½Ğ¾Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ Ñ Ğ²Ñ‹Ğ´ĞµĞ»ĞµĞ½Ğ½Ñ‹Ğ¼ FastAPI Ğ±ÑĞºĞµĞ½Ğ´Ğ¾Ğ¼:

### 1. ĞĞ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

```
mrbets/
â”œâ”€â”€ frontend/            # Next.js frontend
â”‚   â”œâ”€â”€ src/             # React ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Ğ¸ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ globals.css
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”‚   â”œâ”€â”€ public/          # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
â”‚   â”‚   â””â”€â”€ package.json     # Frontend Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
â”‚   â”œâ”€â”€ backend/             # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ app/             # FastAPI ĞºĞ¾Ğ´
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py      # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ‚Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°
â”‚   â”‚   â”‚   â”œâ”€â”€ routers/     # API Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ñ‹
â”‚   â”‚   â”‚   â”œâ”€â”€ models/      # Ğ¡Ñ…ĞµĞ¼Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… 
â”‚   â”‚   â”‚   â””â”€â”€ utils/       # Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹
â”‚   â”‚   â”œâ”€â”€ jobs/            # Cron Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ scan_fixtures.py
â”‚   â”‚   â”‚   â””â”€â”€ worker.py
â”‚   â”‚   â”œâ”€â”€ fetchers/        # Ğ¡Ğ±Ğ¾Ñ€Ñ‰Ğ¸ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚   â”‚   â””â”€â”€ requirements.txt # Backend Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
â”‚   â”œâ”€â”€ monitoring/          # Prometheus Ğ¸ Grafana
â”‚   â”œâ”€â”€ docker-compose.yml   # Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²ÑĞµĞ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹
â”‚   â””â”€â”€ .env.example         # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
```

### 2. Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ±ÑĞºĞµĞ½Ğ´Ğ° (FastAPI)

- **FastAPI App**: REST API Ñ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾ Ğ¼Ğ°Ñ‚Ñ‡Ğ°Ñ… Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ°Ñ…
- **Fixture Router**: `/fixtures` ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ¼Ğ°Ñ‚Ñ‡Ğ°Ğ¼Ğ¸
- **Worker Process**: ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸Ğ· Ğ¾Ñ‡ĞµÑ€ĞµĞ´Ğ¸ Redis
- **Scan Fixtures Job**: ĞŸĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¼Ğ°Ñ‚Ñ‡ĞµĞ¹ (`backend/jobs/scan_fixtures.py`)
- **Fetcher Modules**: Scripts like `backend/fetchers/metadata_fetcher.py` (teams, players), `backend/fetchers/rest_fetcher.py` (API-Football fixture details), `backend/fetchers/scraper_fetcher.py` (news), and `backend/fetchers/odds_fetcher.py` (The Odds API) for data collection.

### 3. ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°

- **Prometheus**: Ğ¡Ğ±Ğ¾Ñ€ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº ÑĞ¾ Ğ²ÑĞµÑ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²
- **Grafana**: Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¸ Ğ°Ğ»ĞµÑ€Ñ‚Ğ¸Ğ½Ğ³

### 4. Docker Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ

- Docker Compose Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ²ÑĞµÑ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²:
  - frontend
  - backend
  - worker
  - redis
  - prometheus
  - grafana

Ğ­Ñ‚Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ ÑƒĞ¿Ñ€Ğ¾Ñ‰Ğ°ĞµÑ‚ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½ÑƒÑ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞµĞ³Ğ¾ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¼Ğ°Ñ‚Ñ‡ĞµĞ¹ Ğ¸ Ğ±Ğ¾Ğ»ĞµĞµ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾Ğ¹ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°.
